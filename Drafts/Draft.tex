\documentclass[12pt]{pom_thesis}
\input{commands_packages}
\usetikzlibrary{decorations.pathreplacing,angles,quotes}
\usepackage{mathrsfs}
\usepackage[euler-digits]{eulervm} %TODO: Maybe change this
\author{Leo Selker}
\advisor{Vin de Silva}
\title{M\"obius Inversion: Construction and Applications}

\newcommand{\fix}{\text{fix }}
\newcommand{\cl}{\text{cl }}
\DeclareMathOperator{\cat}{cat}
\DeclareMathOperator{\ps}{\mathscr{P}}
\DeclareMathOperator{\sub}{Sub}
\DeclareMathOperator{\stab}{Stab}
\DeclareMathOperator{\orb}{Orb}
\DeclareMathOperator{\fixx}{fix}
\DeclareMathOperator{\obj}{ob}
\begin{document}

\maketitle

\begin{abstract}M\"obius inversion is a general approach to reversing certain kinds of sums. In many situations, we know that a value we have access to is equal to the sum over a poset interval of values we want. M\"obius inversion is a tool which allows us to access those summed values. Here, we first develop the theory of M\"obius inversion on arbitrary posets. Then, we investigate its application in various counting examples, including the inclusion-exclusion principle and counting orbits of group actions. Finally, we explore an application of M\"obius inversion to data clustering.
\end{abstract}

\pagenumbering{roman}
\tableofcontents

\newpage
\pagenumbering{arabic}
\begin{chapter}{Introduction to M\"obius Inversion}\label{chap_intro}
\section{Initial Example}
M\"obius inversion is a general construct. The most basic definition of a M\"obius function is a function $\mu$ on the positive integers which satisfies the following for functions $f,g$ on the positive integers:

\begin{equation}\label{init_mob} %TODO: Unify numbering
f(n) = \sum_{d | n} g(d) \iff g(n) = \sum_{d | n}  f(n)\mu\left(\frac dn\right)
\end{equation}

Our first goal is to prove the existence of - and find - this function $\mu$. We will do this using a more general construction, and then generalize to more even more abstract structures. We start with several definitions.
\section{Posets and Incidence Algebras}
\begin{defn}
A \emph{partially ordered set}, often called a \emph{poset}, is a set $X$ together with a binary relation $\leq$, such that, for all $a,b,c \in X$:
\begin{itemize}
\item $a \leq a$ (reflexive)
\item If $a \leq b$ and $b \leq a$ then $a = b$ (antisymmetric)
\item If $a \leq b$ and $b \leq c$ then $a \leq c$ (transitive).
\end{itemize}
\end{defn}
\begin{defn}
A poset $X$ is \emph{lower finite} if, for any $a \in x$, the set $\{ c \in X: c \leq a\}$ is finite.
\end{defn}
\begin{rmk}
A poset which is lower finite is also \emph{locally finite}: For any $a,b \in X$, the set $\{c \in X : a \leq c \leq b\}$ is finite.  
\end{rmk}
For many of the following definitions and theorems, it is enough for the poset to be locally finite. But we will assume our posets are lower finite, a stronger condition, to make certain steps easier.
\begin{defn}
The \emph{incidence algebra} on a lower finite poset $X$ is over the set of functions from $X \times X$ to $\Rr$ which map $(a,b)$ to zero if $a \nleq b$. So the elements of the incidence algebra are 
\[\{f:X \times X \rightarrow \Rr:a \nleq b \Rightarrow f(a,b) = 0\}
\]
Scalar multiplication and addition are defined pointwise.  Multiplication is denoted by ``*'', and is defined:
\[(f* g)(a,b) = \sum_{a \in X}f(a,c)g(c,b) \left( = \sum_{a \leq c \leq b}f(a,c)g(c,b)\right).\]
\end{defn}
\begin{rmk}
The requirement that $X$ be lower finite ensures that the above sum has a finite number of nonzero terms, so is finite-valued.
\end{rmk}
\begin{rmk}
We use $\Rr$ as the codomain of the functions in the incidence algebra. But this can be generalized to other commutative rings with identity.
\end{rmk}
I include the version with bounds for clarity, but they make no difference, because all other terms will go to zero anyway by the condition on elements. Considering the sum without the bounds, we see that this is identical to matrix multiplication. It will be useful to formalize this:
\begin{lemma}\label{mat_eq}
Let $X$ be a lower finite poset, with $|X|=n$. Choose a total ordering on $X$ such that the partial order is respected - in other words, label the elements with integers such that if $x_i \leq x_j, i \leq j$. Let $f,g$ be elements of the incidence algebra on $X$. Let $F$ be the (possibly infinite) square matrix where $F_{ij}=f(x_i, x_j)$. Define $G$ likewise. Then:
\begin{enumerate}[a)]
\item $F$ and $G$ are upper triangular; and
\item For any $i,j, (f * g)(x_i, x_j)=FG_{ij}$.
\end{enumerate}
\end{lemma}
\begin{proof}
\begin{enumerate}[a)]
\item If $i>j$, by how we defined $F$, $x_i \nleq x_j$. So $F_{ij} = f(x_i, x_j) = 0$. 
\item
The result follows directly from the definition of matrix multiplication. Let $i,j\leq n$ be given. Then:
\begin{align*}
(f * g)(x_i, x_j) &= \sum_{y \in X} f(x_i,y)g(y,x_j)\\
&=FG_{ij}
\end{align*}
\end{enumerate}
\end{proof}


There are several important functions, present in any incidence algebra, which we will need. 
The \textbf{identity function} $\delta$ is defined by 
\[\delta(a,b) = \begin{cases} 1 & a = b \\ 0 & else. \end{cases}
\]
This is equivalent to the identity matrix, with 1's along the main diagonal.

We also define another special function, $\zeta$ (the ``indicator function''):
\[
\zeta(a,b) = \begin{cases} 1 & a \leq b \\ 0 & else. \end{cases}
\]

At this point, \ref{mat_eq} tells us several things about inverses. Since $\delta$ is equivalent to the identity matrix, inverses will coincide with the corresponding matrix inverses. This leads us to the following:
\begin{cor}\label{cor_inv}
Let $X$ be a lower finite poset, and let $f,g, h$ be elements of the incidence algebra on $X$. Then:
\begin{enumerate}[a)]
\item $(f*g)*h = f*(g*h)$, i.e. multiplication is associative
\item $f*g = \delta \Rightarrow g*f = \delta$
\item If $\forall x \in X, f(x,x) \neq 0$, then $f$ is uniquely invertible - in other words, $\exists! f^{-1}$ such that $f*f^{-1} = \delta = f^{-1} * f$.
\end{enumerate}
\end{cor}
\begin{proof}
Part a) is true of matrix multiplication in general. Part b) is true of all square matrices. Part c) is true of all upper triangular matrices, since the determinant of such matrices is the product of the main diagonal elements. We use \ref{mat_eq} to transfer all three results to $f$ and $g$.
\end{proof}
We will refer to this unique inverse, if it exists, as $f^{-1}$. 


\section{Definition of M\"obius Inversion}
We are now ready to define the M\"obius function on partially ordered sets.
\begin{defn}\label{def_mob_pos}
Let $X$ be a lower finite poset. Let $\zeta$ be the indicator function defined above. Let $\mu = \zeta^{-1}$. Then $\mu$ is the \emph{M\"obius function} on $X$.
\end{defn}
\begin{rmk}
This inverse exists by \ref{cor_inv} part b. 
\end{rmk}
\begin{rmk}\label{sum_form}
Definition \ref{def_mob_pos} is a statement about incidence algebra multiplication, so is really about matrix multiplication. Another statement of the definition is that $\mu$ is the unique function such that, for all $x,y \in X$,
\[
\sum_{z \in X} \mu(x,z)\zeta(z,y) = \delta(x,z) = \sum_{z \in X} \zeta(x,z)\mu(z,y)
\]
\end{rmk}

This is the M\"obius function. To complete the definition of M\"obius inversion, we turn to the standard use of this function. 
\begin{thm}[M\"obius Inversion]\label{mob_inv}
Let $X$ be a lower finite poset. Let $f, g: X \times X \rightarrow \Rr$ be elements of the incidence algebra on $X$. Let $\zeta, \mu$ be defined as usual. Then:
\begin{align*}
f = g * \zeta &\iff g = f *\mu;\\
f = \zeta * g &\iff g = \mu * f.
\end{align*}
Equivalently,
\begin{align*}
\forall x,y \in X, f(x,y) = \sum_{z \in X}g(x,z)\zeta(z,y) &\iff \forall x,y \in X, g(x,y) = \sum_{z \in X}f(x,z)\mu(z,y);\\
\forall x,y \in X, f(x,y) = \sum_{z \in X}\zeta(x,z)g(z,y) &\iff \forall x,y \in X, g(x,y) = \sum_{z \in X}\mu(x,z)f(z,y).
\end{align*}
\begin{proof}
All these results follow from the definition of $\mu$ and from facts about matrix/incidence algebra multiplication.
\end{proof}
\end{thm}
This result seems quite straightforward based on how we defined $\zeta$ and $\mu$. However, it turns out to be extremely powerful. We will see many cases where values of $f$ from the theorem are readily attainable, but values of $g$ are what we really want. The M\"obius function allows us to obtain those values. This procedure - the use of the M\"obius function to reverse the process of summing terms as in theorem \ref{mob_inv} - is what is referred to as M\"obius inversion.

With that in mind, we can also consider M\"obius inversion on functions in one variable (instead of two) on a poset.
\begin{thm}\label{1var_mob_inv}
Let $X$ be a lower finite poset. Let $f,g:X \rightarrow \Rr$ be given. Let $\zeta, \mu$ be defined as usual. Then:
\begin{align*}
f = g *\zeta & \iff g = f *\mu;\\
f = \zeta *g & \iff g = \mu *f.
\end{align*}
Equivalently,
\begin{align*}
\forall x \in X, f(x) = \sum_{y \in X} g(y)\zeta(y,x) &\iff \forall x \in X, g(x) = \sum_{y \in X} f(y)\mu(y,x);\\
\forall x \in X, f(x) = \sum_{y \in X} \zeta(x,y)g(y) &\iff \forall x \in X, g(x) = \sum_{y \in X} \mu(x,y)g(y).
\end{align*}
\end{thm}
\begin{proof}
If we fix one argument of functions on two variables, this follows from \ref{mob_inv}.
\end{proof}
We now have two equivalent definitions of the M\"obius function, one using matrices (or linear operators) and vectors, and one directly considering elements and sums. We will continue to move back and forth between these two approaches throughout this investigation. This is because although the two definitions are completely equivalent, they each have advantages. Working with sums and elements helps us see the details of what is going on, and reminds us of the structure of our poset. It is also often the perspective from which motivating problems arise. On the other hand, using matrices and vectors greatly simplifies the equations we have to deal with, makes the manipulations themselves easier, and allows us to keep the bigger picture - the idea of inversion - in mind more easily. 

\section{Integers with Divisibility Ordering}
We are now able to justify the existence of, and find, the function $\mu$ from equation \ref{init_mob}, with very little work.

We will consider the set $\Nn$ as a poset ordered by divisibility. For our purposes, $0 \notin \Nn$. Note that this poset is lower finite: For any number $n$, the set $\{q \in \Nn: q|n\} \subseteq \{q \in \Nn: q \leq n\}$, and the latter set contains $n$ elements, which is finite. This means we are able to use M\"obius inversion.

We go through the usual steps of M\"obius inversion and apply \ref{mob_inv}. We will use functions and sums rather than matrices and vectors to make it easier to see what is going on.
\begin{itemize}
\item Let $\zeta: \Nn \times \Nn \rightarrow \Nn$ be defined as follows. Note that $m|n$ means that $m$ divides $n$ without remainder.
\[
\zeta(m,n) = \begin{cases}1 & m|n \\ 0 & else \end{cases}
\]
\item Let $\mu = \zeta^{-1}$ (inverse in the incidence algebra)
\end{itemize}
Then \ref{1var_mob_inv} gives us:
\[
g(n) = \sum_{d | n} g(d) \iff g(n) = \sum_{d | n}  f(d)\mu(d,n)
\]
This is almost what we want, but not quite. Here $\mu$ is a function in two variables, while in \ref{init_mob} it is a function in a single variable. It turns out that values of $\mu(d,n)$ will only depend on $\frac nd$, which will gives us the desired form. To see that, we start by writing down a recursive form which works for any M\"obius function.

\begin{lemma}\label{recurse}
Let $X$ be a lower finite partially ordered set, and let $\zeta, \mu$ be defined as usual. Then for all $a, b \in X$,
\[
\mu(a,b) = 
\begin{cases}
0 & a \nleq b\\
\delta(a,b)-\sum_{a \leq c < b}\mu(a,c) & else.
\end{cases}
\]
\end{lemma}
\begin{rmk}
Note that the piecewise form is actually not necessary, because if $a \nleq b$ then the sum will be empty. So it is correct - albeit less clear- to just write
\[
\mu(a,b) = \delta(a,b)-\sum_{a \leq c < b}\mu(a,c).
\]
\end{rmk}
\begin{proof}
We fix $a,b$, and then rearrange terms starting from \ref{sum_form}:
\begin{align*}
\sum_{c \in X}\mu(a,c) \zeta(c,b) &= \delta(a,b)\\
\sum_{a \leq c < b} \mu(a,c) + \mu(a,b) &= \delta(a,b)\\
\mu(a,b) &= \delta(a,b) - \sum_{a \leq c < b} \mu(a,c) 
\end{align*}
\end{proof}
We are now ready to write down $\mu$ in the context of the divisibility lattice poset. 

\begin{lemma}\label{nfact}
Let $\zeta, \mu$ be defined as usual on $\Nn$ ordered by divisibility. Let $m,n \in \Nn$ be given.  Then:
\[
\mu(m,n) =
\begin{cases}
0 & m\nmid n\\
0 & \exists p \in \Nn: p^2|(\frac nm )\\
(-1)^{\#\{p \text{ prime}: p|\frac nm\}} & else
\end{cases}
\]
\end{lemma}
This lemma gives us what we need - a way of writing values of $\mu$ in terms of a single variable. We will prove it by induction on the number of prime factors of $\frac nm$.
\begin{proof}
If $n \nmid m$, then by \ref{recurse}, $\mu(m,n) = 0$. This is the first case.

If $n = m$, then $\frac nm=1$ has zero prime factors. In that case, again by \ref{recurse}, $\mu(n,m) = 1$. This will be our base case for the second and third branches.

Suppose that if $m|n$, and $\frac nm$ has $k$ prime factors (with multiplicity), then \ref{nfact} holds for $m$ and $n$. Suppose that $m_0|n_0$ and $\frac nm$ has $k+1$ prime factors. We now consider three cases.
\begin{description}
\item[Case 1:] Suppose that $\frac nm$ has no squared prime factors. 
\end{description}
\end{proof}

\end{chapter}

\begin{chapter}{Groups and Orbits} 
\section{Background}
NOTE: Define groups, actions, orbits, subgroups, etc. (do I need to?)

I will use $G(x)$ to denote $x$'s orbit under $G$, and $\orb(\Omega, G)$ to denote the set of orbits in $\Omega$ under $G$'s action on it. 
\section{M\"obius Inversion on Poset of Subgroups}
We want to apply M\"obius inversion to finite groups. This means we will need a poset. We will use the \emph{poset of subgroups} (or \emph{lattice of subgroups}):
\begin{defn}
Let $G$ be a finite group. Then let the \textit{poset of subgroups} of $G$, or $\sub(G)$, be the poset consisting of subgroups of $G$ \emph{reverse} ordered by inclusion. In other words, we say that $A \leq B$ if $A \supseteq B$.
\end{defn}
\begin{rmk}
Because $G$ is finite, $\sub(G)$ is finite (so lower finite).
\end{rmk}
\begin{rmk}
We are ordering the poset this way for reasons that will soon become clear. But to reduce confusion, we will continue to use inclusion notation to define $\zeta$, and so $\mu$, rather than using $\leq$. Also note that I will be using $\subseteq$ rather than $\leq$ to denote subgroups, also to reduce confusion with the poset relation.
\end{rmk}
This puts us in the position to apply M\"obius inversion. We will use the form of M\"obius inversion with matrices and vectors. So throughout this chapter:
\begin{itemize}
\item Given a group $G$, assume a total ordering of $\sub(G)$ which respects the partial ordering. Let $\zeta$ also denote the square matrix of size $|\sub(G)|$, with rows and columns labeled with elements of $\sub(G)$, such that 
\[
\zeta_{A,B} = \begin{cases}
1 & A \supseteq B\\
0 & else
\end{cases}
\]
\item Let $\mu = \zeta^{-1}$, which exists by \ref{cor_inv}.
\end{itemize}
Now, \ref{1var_mob_inv} tells us that, for any row vectors $f,g$ of length $|\sub{G}|$, 
\[
f = g\zeta \iff g = f\mu.
\]
\section{Counting Orbits}
Throughout this section, let $G$ be a finite group acting on a set $\Omega$.

We start by defining some vectors, each with entries corresponding with subgroups of $G$, which we will be using. Let:
\begin{align*}
f_A &= \#\{x \in \Sigma: \stab(x) \supseteq A\} = |\fix(A)|\\
g_A &= \#\{x \in \Sigma: \stab(x) = A\}
\sigma_A &= |A|
\end{align*}

What now? The goal is to count the orbits in $\Omega$ under the action by $G$ - in other words, to find $|\orb(\Omega, G)|$. We will start with the assumption that we are able to find $f$ and $\sigma$, which is true if we know the structure of $\sub(G)$ and know the group action. Then there are two steps we will follow:
\begin{description}
\item[Step 1:] Determine how to use $g$ and $\sigma$ to find $|\orb(\Omega, G)|$; and
\item[Step 2:] Find $g$ from $g$.
\end{description}

Suppose we are handed $g$. In order to see how to find $|\orb(\Omega, G)|$, we recall a basic fact from group theory, which holds for any $x \in \Omega$:
\begin{fact}
\[|G| = |G(x)||\stab(x, G)|\]
\end{fact}
Because $G$ is finite, this implies that \[|G(x)| = \frac{|G|}{|\stab(x, G)|}.\]

Starting from a trivial fact, we have:
\begin{align*}
|\orb(\Omega, G)| &= \sum_{O \in \orb(\Omega, G)}1\\
&= \sum_{O \in \orb(\Omega, G)}\left(\sum_{x \in O}\frac{1}{|O|}\right)\\
&= \sum_{x \in \Omega}\frac{1}{|G(x)|}
\end{align*}

Substituting, we now have the relationship:
\[
|\orb(\Omega, G)| = \frac{1}{|G|}\sum_{x \in \Omega}|\stab(x, G)|
\]
Each element of $\Omega$ has exactly one stabilizer in $G$. This means that we can partition the above sum as follows:
\[
|\orb(\Omega, G)| = \frac{1}{|G|}\sum_{A \in \sub(G)}\left(\sum_{x \in \Omega: \stab(x) = A}|A|\right)
\]
Using the definitions of $g$ and $\sigma$, we can rewrite to get the relationship we need:
\begin{align*}
|\orb(\Omega, G)| &= \frac{1}{|G|}\sum_{A \in \sub(G)}g_A|A|\\
&= g \cdot \sigma
\end{align*}

On to Step 2. It is clear that $f_A = \sum_{B \supseteq A} g_A$. Another way of putting that is that $f = g\zeta$. As usual, this implies that $g = f\mu$. So M\"obius inversion makes this step trivial. Putting it all together:

\[
|\orb(\Omega, G)| = f\mu \cdot \sigma
\]
\section{Burnside's Lemma}
A more familiar way of counting the orbits of a group is the following:
\begin{thm}[Burnside's Lemma]\label{burnside}
Let $G$ be a finite group acting on a finite set $\Omega$. Then:
\[
|\orb(\Omega, G) = \frac{1}{G}\sum_{g \in G}\fixx(g)
\]
\end{thm}

\end{chapter}

\begin{chapter}{Inclusion-Exclusion}
\section{Introduction}
We start by introducing the desired end result, the \emph{inclusion-exclusion principle}:
\begin{thm}[Inclusion-Exclusion]\label{iep}
Let $S$ be a set. Let $A_i \subseteq S$ for each $i \in I$ where $I$ is finite. Let $K \subseteq I$ be given. Then
\[
\bigcup_{i \in K}A_i = \sum_{J \subseteq K}(-1)^{|J|}\bigcap_{i \in J}A_j
.\]
\end{thm}
\section{Proof using Mobius Inversion}
There are many proofs of this well-known fact. We will show it using M\"obius inversion. This means we will need a poset. Throughout this section, we will have the following setup: Let $S$ be a finite set. Let $I$ be a finite index set, and for all $i \in I$, let $A_i \subseteq S$. We will be manipulating functions on subsets of $I$, so this will be our poset.
\section{Generalizations}
%TODO: Connect with integer divisibility

\end{chapter}
\begin{chapter}{Metric Space Magnitude}
\section{Motivation: Clustering}
The \emph{magnitude} of a metric space is a notion introduced in \cite{Lein2}. %TODO: Finish introduction
\section{Important Definitions} \label{mag_defs}
A metric space is a space with a notion of distance between pairs of points. 
\begin{defn}
A \textit{metric space} $(M,d)$ is a set $M$ together with a function  $d:M \times M \rightarrow \Rr$ (the \emph{metric}), such that the following are satisfied for all $a,b,c \in M$:
\begin{itemize}
\item $d(a,b) \geq 0$, with equality $\iff a = b$;
\item $d(a,b) = d(b,a)$; and
\item $d(a,b) + d(b,c) \geq d(a,c)$.
\end{itemize}
We sometimes write just $M$ if the metric is unambiguous.
\end{defn}
A category is an algebraic structure which generalizes ``objects" and ``maps" (or ``morphisms"), with composition. There are several equivalent definitions, all somewhat technical, but the construct itself is quite intuitive once you get used to it.  
\begin{defn}
A \textit{category} $C$ consists of:
\begin{itemize}
\item A collection $C_0$ of \emph{objects};
\item For each $a,b \in C_0$, a collection $C(a,b)$ of \emph{morphisms from $x$ to $y$};
\item For each $a,b,c \in C_0$, a \emph{composition operator}: A function $\circ:C(a,b) \times C(b,c) \rightarrow C(a,c)$; and
\item For each $a \in C_0$, an \emph{identity morphism} $1_a \in C(a,a)$,
\end{itemize}
such that the following axioms are satisfied:
\begin{itemize}
\item Composition is associative: If $a,b,c,d \in C_0$ and $f\in C(a,b), g \in C(b,c), h \in C(c,d)$, then $f \circ (g \circ h) = (f \circ g) \circ h$, and
\item Composition respects identities: If $a,b \in C_0, f \in C(a,b)$, then $1_b \circ f = f = f \circ 1_a$.
\end{itemize}
\end{defn}
This is a definition of what is usually called a category, but here we will refer to it as an \emph{ordinary} category. This is because it will also be useful to mention a generalization of categories, called \emph{enriched categories}. The idea is that we replace the sets of morphisms with objects from an ordinary category of a certain type, and adapt the definition of composition accordingly. We will be using a particular kind of enriched category, called a \textit{generalized metric space}.

It's not necessary to fully understand how generalized metric spaces are categories - every space we consider here will be a bona fide metric space. Furthermore, the definitions and constructions we explore will be easy to apply directly to metric spaces. I point out that this construction is a type of category to justify dealing with them together with other categories in the next section. We will define the Euler characteristic of a category, and we will need to apply the definition to metric spaces by way of generalized metric spaces. This will make much more sense if we keep in mind that generalized metric spaces are categories.

The full definition of enriched categories is complicated, technical, and not necessary here. For a full discussion of enriched categories, see \cite{Kelly1}. We will instead directly define a particular enriched category object called a \emph{generalized metric space}.
\begin{defn}
A \emph{generalized metric space} $C$ consists of:
\begin{itemize}
\item A collection $M$ of points (or objects); and
\item For each $a,b \in M$, a non-negative real number $d(a,b)$, such
\end{itemize}
such that, for all $a,b \in M$,
\[C(a,a) = 0,\hspace{1cm} C(a,b) + C(b,c) \geq C(a,c).
\]
\end{defn}
Note that this is essentially the same as a metric space, but without the restriction that distinct points have nonzero distance, and without the requirement of symmetry. Relaxing these constraints allows us to cleanly express this as an enriched category. In keeping with the intuitive description of enriched categories which I gave earlier, this is a category where sets of morphisms are replaced by non-negative real numbers. The two axioms are enforced by details in the definition of an enriched category which I swept under the rug.

For those who are interested in the details, what we are doing is letting $\mathcal{V}$ be the monoidal category whose set of objects is $\Rr^{\geq 0}$, with a single morphism from $a$ to $b$ if and only if $a \leq b$, and with addition (+) as the monoid operator. Then a generalized metric space is a category enriched with $\mathcal{V}$. 

We will soon be interested in a notion of how close together things are - and it will need to measure closeness rather than distance, in the sense that it will increase for objects which are closer together. The reason for this will become clear soon. We will call this binary function $\zeta$, and define it on a category $C$ as follows: For $a,b \in C_0$, if $C$ is an ordinary category, then $\zeta(a,b) = |C(a,b)|$, or the size of the set of morphisms from $a$ to $b$. If $C$ is a generalized metric space, then $\zeta(a,b) = e^{-C(a,b)}$. 

The definition for ordinary categories is fairly natural. The version for generalized metric spaces is less intuitive, but the definitions are surprisingly consistent. Consider three objects $a,b,c$ in an ordinary category. The numbers above the arrows indicate the number of morphisms between adjacent objects:

\[
\begin{tikzpicture}[auto, node distance = 3cm, main node/.style={dot}]

\node[label = below:{a}, circle, draw, fill=black,
                        inner sep=0pt, minimum width=4pt](1) at (0,0) {};
\node[label = below:{b}, circle, draw, fill=black,
                        inner sep=0pt, minimum width=4pt](2) at (3,0) {};
\node[label = below:{c}, circle, draw, fill=black,
                        inner sep=0pt, minimum width=4pt](3) at (6,0) {};                        

\draw[-latex] (1) -- (2) node[midway, above = 3pt] {\textit{k}};
\draw[-latex] (2) -- (3) node[midway, above = 3pt] {\textit{l}};

\end{tikzpicture}\]
Then, as a result of the composition axioms, there must be a morphism $g \circ f$ from $a$ to $c$ for each pair of morphisms $f \in C(a,b), g \in C(b,c)$. This means that there are $kl$ morphisms from $a$ to $c$ which are implied by the morphisms shown above. So $\zeta(a,c) \geq \zeta(a,b)  \zeta(b,c)$. 

Now, consider the same situation in a generalized metric space. We know from one of the axioms that
\[
C(a,c) \leq C(a,b) + C(b,c).
\]
The inverse exponential function is monotonically decreasing. So we simply apply it to both sides and flip the inequality to get the same result, that $\zeta(a,c) \geq \zeta(a,b) \zeta(b,c)$.

There is another way of looking at essentially the same property. The reason the addition (+) operator appears in the second axiom in the generalized metric space definition is because addition is what is called the \textit{monoidal product} in the enriched category. The equivalent in an ordinary category is the tensor product, $\otimes$. In terms of number of morphisms, $\otimes$ behaves like multiplication. We want a fact about addition to give us a fact about multiplication. Exponentiating is the most natural way to translate multiplication into addition, so we can apply the axiom.
\section{M\"obius Inversion on a Category}
To define M\"obius inversion on a partially ordered set, we used an "indicator function" which was - not coincidentally - notated as $\zeta$. We will henceforth refer to this function as $\zeta'$, reserving $\zeta$ for the function we just defined on categories. Recall that for $a,b$ in a poset $X$, $\zeta'(a,b)$ was defined to be 1 if $a \leq b$, and 0 otherwise. We would like to generalize the construction of M\"obius inversion. The first step is to observe the following: Given a poset $X$, we can construct an "equivalent" category by letting $C_0=X$, and adding a single morphism from elements $a,b \in C_0$ if and only if $a \leq b \in X$. It is easily checked that this is in fact a category, and that for each triplet in $C_0$ there is only one possible composition operator (this is why we don't bother to explicitly define them). 

The key fact here is that for $a,b \in C_0 = X, \zeta(a,b) = \zeta'(a,b)$. This motivates the following definition:
\begin{defn}\label{cat_mob} %TODO: Check uniqueness
Let $C$ be a category. Let $\zeta$ be as defined above. Then the \emph{M\"obius function} on $C$, if it exists, is a function $\mu$ which, for all $x,y \in C$, satisfies
\[
\sum_{z \in X} \mu(x,z)\zeta(z,y) = \delta(x,z) = \sum_{z \in X} \zeta(x,z)\mu(z,y).
\]
If such a $\mu$ exists, $C$ is said to \emph{have M\"obius inversion}. %TODO: Connect back, use matrix version
\end{defn}
\section{Euler Characteristic of a Category}
\subsection{Definition}
We are now ready to construct central definition of this section: the Euler characteristic of a category. The entire construction can be found in \cite{Lein1, Lein2, Lein4}. 

Throughout this section, objects declared as categories are implicitly allowed to be either ordinary categories or generalized metric spaces. The definition of $\zeta$ from section \ref{mag_defs} will be assumed.

\begin{defn}
A \emph{weighting} on a category $\Aa$ is a function $w_a$ on $\obj(\Aa)$ such that for all $a \in \Aa$,
\[
\sum_b \zeta(a,b)\omega_b = 1.
\]
\end{defn}

\begin{lemma}
\label{mobius_is_weighting}
If $\Aa$ has M\"obius inversion, then $\omega_a = \sum_b \mu(a,b)$ is a weighting on $\Aa$.
\end{lemma}
\begin{proof} For all $a \in \Aa$,
\begin{align*}
\sum_b \zeta(a,b)\omega_b &= \sum_b\left( \zeta(a,b)\sum_c \mu(b,c)\right)\\
&=\sum_b\sum_c\zeta(a,b)\mu(b,c)\\
&=\sum_c\left(\sum_b\zeta(a,b)\mu(b,c)\right)\\
&=\sum_c \delta(a,c)\\
&=1.
\end{align*}
\end{proof}

This is important. It provides a way in which we can write down weightings on metric spaces, since the similarity matrix $\zeta$ is invertible in many cases. We will investigate exactly which cases when we discuss positive semidefinite matrices.

The following definition is due to \cite{Lein1}.
\begin{defn}
Let $\omega$ be a weighting on a finite category $A$. Then the \emph{Euler characteristic} of $A$, denoted by $\chi(A)$, is defined by
\[
\chi(A) = \sum_{a \in A} \omega_a
\]
\end{defn}
Note that even if a category admits several weightings, they all lead to the same Euler characteristic by a simple sum rearrangement argument. Together with \ref{mobius_is_weighting}, this implies the following:
\begin{cor}
If a finite category $A$ has a M\"obius inversion $\mu$, then
\[\chi(A) = \sum_{a \subseteq A} \sum_{b \subseteq A} \mu(a, b).
\]
\end{cor}

\subsection{Simplicial Complexes}
Calling a new construction an Euler characteristic needs some intuitive justification. We will a structure called a \textit{simplicial complex} to show that calling this value an Euler characteristic is reasonable. 

%TODO: Define simplicial complex

\begin{defn}
Let $\sigma$ be a simplicial complex. Then the \emph{category generated by $\sigma$}, or $\cat(\sigma)$, is the category whose objects are the cells of $\sigma$. If $\gamma$ and $\omega$ are cells of $\sigma$, then $|(\gamma, \omega)| = 1$ if $\gamma \subseteq \omega$ and 0 else.
\end{defn}
\begin{lemma}
\label{mu_lemma}
Suppose $\alpha \subseteq \beta$ are cells of a simplicial complex. Then $\mu(\cat(\alpha), \cat(\beta)) =(-1)^{|\beta - \alpha|} = (-1)^{|\alpha|} (-1)^{|\beta|}$.
\end{lemma}
\begin{proof}
We use induction. Base case: $\sigma = \beta$, \checkmark \\
For any simplex $\sigma$, let $\sigma'$ be $\sigma \cup \emptyset$. Suppose that $|\beta - \alpha| = k+1$. We know that \begin{align*}
\mu(\alpha, \beta) &=  - \sum_{\alpha \subseteq \sigma \subset \beta} \mu(\alpha, \sigma)\\
&= - \sum_{\gamma \subset (\beta - \alpha)'} \mu(\alpha, \gamma \cup \alpha) 
\end{align*}
Note that the above unions are always disjoint. So, by the inductive hypothesis, we can rewrite it:
\begin{align*}
\mu(\alpha, \beta) &= - \sum_{\gamma \subset (\beta - \alpha)'} (-1)^{|\gamma \cup \alpha| - |\alpha|} \\ %& \text{inductive hypothesis}\\
&= - \sum_{\gamma \subset (\beta - \alpha)'} (-1)^{|\gamma|}\\ % &\text{by disjointness}\\
&= - \sum_{\gamma \subseteq (\beta - \alpha)} (-1)^{|\gamma|} + (-1)^{|\beta - \alpha|} - (-1)^0 \\ %&\text{Removing the empty simplex and including $\gamma = \beta - \alpha$}\\
&= \chi(\beta - \alpha) + (-1)^{|\beta - \alpha|} - (-1)^0\\
&= 1-1+ (-1)^{|\beta - \alpha|}\\
&= (-1)^{|\beta - \alpha|}
\end{align*}


\end{proof}
\begin{thm}
\label{consistentEuler}
Let $\sigma$ be a simplicial complex. Then 
\[
\sum_{\gamma \subseteq \sigma} \sum_{\alpha \subseteq \gamma} \mu(\alpha, \gamma) = \chi(\sigma).
\]

\end{thm}
\begin{proof}

\begin{align*}
\sum_{\gamma \in \sigma} \sum_{\alpha \subseteq \gamma} \mu(\alpha, \gamma) &= \sum_{\gamma \in \sigma} \sum_{\emptyset \subset \alpha \subseteq \gamma} \mu(\alpha, \gamma)\\
&= \sum_{\gamma \in \sigma} \mu(\emptyset, \gamma)\\
&= \sum_{\gamma \in \sigma} (-1)^{|\gamma|} &\text{by \ref{mu_lemma}}\\
&= \chi(\sigma)
\end{align*}
\end{proof}
This implies the comforting fact that $\chi(\cat(\sigma)) = \chi(\sigma)$.
\section{Metric Space Magnitude}
\subsection{Motivation: Hierarchical Clustering}
\subsection{Idea and Definition}
\subsection{Product Spaces}
\subsection{Examples}
\end{chapter}


\bibliographystyle{abbrv}
\bibliography{bibliography.bib}


\end{document}

